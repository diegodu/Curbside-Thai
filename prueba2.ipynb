{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prueba2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegodu/Curbside-Thai/blob/master/prueba2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux7DudwVI6ic",
        "colab_type": "text"
      },
      "source": [
        "En esta line se aplica para poder aumentar la ram del google colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV8Ddq81vSaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = [] \n",
        "while (1): \n",
        "    a.append ('1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cU-42HwYhCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBbGADzMn-YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "from sklearn import preprocessing "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc0rG37YJZGg",
        "colab_type": "text"
      },
      "source": [
        "Importamos numpy para poder trabajar con esta libreria"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdLKDz5PNN13",
        "colab_type": "code",
        "outputId": "2beedf17-c79f-4532-97a0-2db218f9e019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load dataset into Pandas DataFrame\n",
        "df = pd.read_csv('/content/fertility_Diagnosis.csv', names=['Temporada','Edad','Enf-infantiles','Accidente','Int-Quirurgica','Fiebres','Consumo-alchol','habito-fumar',' horas-sentado','Salida'])\n",
        "df.head()\n",
        "#Temporada en la que se realizó el análisis. 1) invierno, 2) primavera, 3) verano, 4) otoño. (-1, -0.33, 0.33, 1)\n",
        "#Edad al momento del análisis. 18-36 (0, 1)\n",
        "#Enfermedades infantiles (es decir, varicela, sarampión, paperas, polio) 1) sí, 2) no. (0, 1)\n",
        "#Accidente o trauma grave 1) sí, 2) no. (0, 1)\n",
        "#Intervención quirúrgica 1) sí, 2) no. (0, 1)\n",
        "#Fiebres altas en el último año 1) hace menos de tres meses, 2) hace más de tres meses, 3) no. (-1, 0, 1)\n",
        "#Frecuencia de consumo de alcohol 1) varias veces al día, 2) todos los días, 3) varias veces a la semana, 4) una vez a la semana, 5) casi nunca o nunca (0, 1)\n",
        "#hábito de fumar 1) nunca, 2) ocasionalmente 3) diariamente. (-1, 0, 1)\n",
        "#Número de horas que pasa sentado por día ene-16 (0, 1)\n",
        "#Salida: diagnóstico normal (N), alterado (O)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temporada</th>\n",
              "      <th>Edad</th>\n",
              "      <th>Enf-infantiles</th>\n",
              "      <th>Accidente</th>\n",
              "      <th>Int-Quirurgica</th>\n",
              "      <th>Fiebres</th>\n",
              "      <th>Consumo-alchol</th>\n",
              "      <th>habito-fumar</th>\n",
              "      <th>horas-sentado</th>\n",
              "      <th>Salida</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.94</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.31</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.38</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.67</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Temporada  Edad  Enf-infantiles  ...  habito-fumar   horas-sentado  Salida\n",
              "0      -0.33  0.69               0  ...             0            0.88       N\n",
              "1      -0.33  0.94               1  ...             1            0.31       O\n",
              "2      -0.33  0.50               1  ...            -1            0.50       N\n",
              "3      -0.33  0.75               0  ...            -1            0.38       N\n",
              "4      -0.33  0.67               1  ...            -1            0.50       O\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOW70d8nskWc",
        "colab_type": "text"
      },
      "source": [
        "Preprocesamiento de la columna Salida"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_daKSjcQmkCH",
        "colab_type": "code",
        "outputId": "3c6cfd4e-9829-4ec5-d13f-ede3c55e1e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "#Preprocesamiento de la columna Salida\n",
        "# Extraer la columna de Salida\n",
        "inputs = np.array(df) \n",
        "Salida= inputs[:,9] \n",
        "print(Salida) \n",
        "# Create label encoder and fit the labels \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "encoder.fit(Salida) \n",
        "# Print the mapping \n",
        "print(\"\\nLabel mapping:\") \n",
        "for i, item in enumerate(encoder.classes_): \n",
        "  print(item, '-->', i) \n",
        "# Encode a set of labels using the encoder\n",
        "encoded_values6 = encoder.transform(Salida) \n",
        "#print(\"\\nLabels =\", workclass)\n",
        "#print(\"Encoded values =\", list(encoded_values6)) \n",
        "df['Salida'] = encoded_values6 \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['N' 'O' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'O'\n",
            " 'N' 'O' 'N' 'N' 'N' 'O' 'N' 'N' 'O' 'O' 'N' 'O' 'N' 'N' 'N' 'N' 'N' 'N'\n",
            " 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N'\n",
            " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'N'\n",
            " 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'N'\n",
            " 'N' 'N' 'N' 'O' 'N' 'N' 'N' 'N' 'N' 'N']\n",
            "\n",
            "Label mapping:\n",
            "N --> 0\n",
            "O --> 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xaPIr8KTH5v",
        "colab_type": "code",
        "outputId": "3f369baf-776b-452e-e649-d2570177a48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "#sacar los atributos necesarios para el estudio\n",
        "df = df.dropna(subset=['Edad', 'Accidente', 'Int-Quirurgica', 'Consumo-alchol', 'habito-fumar'])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temporada</th>\n",
              "      <th>Edad</th>\n",
              "      <th>Enf-infantiles</th>\n",
              "      <th>Accidente</th>\n",
              "      <th>Int-Quirurgica</th>\n",
              "      <th>Fiebres</th>\n",
              "      <th>Consumo-alchol</th>\n",
              "      <th>habito-fumar</th>\n",
              "      <th>horas-sentado</th>\n",
              "      <th>Salida</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.94</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.31</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.67</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Temporada  Edad  Enf-infantiles  ...  habito-fumar   horas-sentado  Salida\n",
              "0      -0.33  0.69               0  ...             0            0.88       0\n",
              "1      -0.33  0.94               1  ...             1            0.31       1\n",
              "2      -0.33  0.50               1  ...            -1            0.50       0\n",
              "3      -0.33  0.75               0  ...            -1            0.38       0\n",
              "4      -0.33  0.67               1  ...            -1            0.50       1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwrTT8UrjEpA",
        "colab_type": "code",
        "outputId": "7dc76f9a-c700-4492-f8de-5b17eb3b2cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "#Seleccionamos las variables escogidas\n",
        "\n",
        "Xsubset = df[['Edad', 'Accidente', 'Int-Quirurgica', 'Consumo-alchol', 'habito-fumar']]\n",
        "\n",
        "#Xsubset.fillna(0)\n",
        "\n",
        "#para separar nuestra variable dependiente de la independiente, haremos lo siguiente:\n",
        "\n",
        "y = df.Salida.values\n",
        "print(Xsubset)\n",
        "type(Xsubset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Edad  Accidente  Int-Quirurgica  Consumo-alchol  habito-fumar\n",
            "0   0.69          1               1             0.8             0\n",
            "1   0.94          0               1             0.8             1\n",
            "2   0.50          0               0             1.0            -1\n",
            "3   0.75          1               1             1.0            -1\n",
            "4   0.67          1               0             0.8            -1\n",
            "..   ...        ...             ...             ...           ...\n",
            "95  0.67          0               0             1.0            -1\n",
            "96  0.61          0               0             0.8             0\n",
            "97  0.67          1               1             1.0            -1\n",
            "98  0.64          0               1             1.0             0\n",
            "99  0.69          1               1             0.6            -1\n",
            "\n",
            "[100 rows x 5 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeFefu4Cl_8E",
        "colab_type": "code",
        "outputId": "e5e70023-b328-48ea-e52b-1e44b52bb4c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#PRIMERA FORMA DE PREPROCESAR\n",
        "\n",
        "preprocesador1 = make_column_transformer(\n",
        "    (StandardScaler(),['Edad','Consumo-alchol']),\n",
        "    (OneHotEncoder(),['Int-Quirurgica','Accidente','habito-fumar']))\n",
        "\n",
        "X = preprocesador1.fit_transform(Xsubset)\n",
        "print(X.shape[1])\n",
        "print(X.shape)\n",
        "\n",
        "#print(X)\n",
        "\n",
        "#print(preprocesador1)\n",
        "categorical_features = ['Int-Quirurgica','Accidente','habito-fumar']\n",
        "cnamesDataset1 = ['Edad','Consumo-alchol']\n",
        "cnamesDataset2 = preprocesador1.transformers_[1][1].get_feature_names(categorical_features)\n",
        "#print(cnamesDataset2)\n",
        "\n",
        "cnamesDataset1.extend(cnamesDataset2)\n",
        "print(cnamesDataset1)\n",
        "\n",
        "DatasetPreprocesado = pd.DataFrame(data=X,columns=cnamesDataset1)\n",
        "print(DatasetPreprocesado.head())\n",
        "\n",
        "DatasetPreprocesado.to_csv(\"DatasetPreprocesado.csv\", sep=\";\",index = False) #sep es el separado, por defector es \",\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "(100, 9)\n",
            "['Edad', 'Consumo-alchol', 'Int-Quirurgica_0', 'Int-Quirurgica_1', 'Accidente_0', 'Accidente_1', 'habito-fumar_-1', 'habito-fumar_0', 'habito-fumar_1']\n",
            "       Edad  Consumo-alchol  ...  habito-fumar_0  habito-fumar_1\n",
            "0  0.173970       -0.192006  ...             1.0             0.0\n",
            "1  2.245043       -0.192006  ...             0.0             1.0\n",
            "2 -1.400045        1.008032  ...             0.0             0.0\n",
            "3  0.671028        1.008032  ...             0.0             0.0\n",
            "4  0.008284       -0.192006  ...             0.0             0.0\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSDMhd5xvZAY",
        "colab_type": "code",
        "outputId": "242fd036-41ac-427e-ca3f-67631c1b4564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "#SEGUNDA FORMA DE PREPROCESAR\n",
        "\n",
        "numeric_features = ['Edad','Consumo-alchol']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['Int-Quirurgica','Accidente','habito-fumar']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder())])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor)])\n",
        "#print(clf)\n",
        "\n",
        "X = clf.fit_transform(Xsubset)\n",
        "print(X.shape[1])\n",
        "print(X.shape)\n",
        "#print(X)\n",
        "#print(clf)\n",
        "\n",
        "cnamesDataset1 = ['Edad','Consumo-alchol']\n",
        "cnamesDataset2 = clf.named_steps['preprocessor'].transformers_[1][1]\\\n",
        "   .named_steps['onehot'].get_feature_names(categorical_features)\n",
        "\n",
        "\n",
        "cnamesDataset1.extend(cnamesDataset2)\n",
        "\n",
        "DatasetPreprocesado = pd.DataFrame(data=X,columns=cnamesDataset1)\n",
        "print(DatasetPreprocesado.head())\n",
        "DatasetPreprocesado.to_csv(\"DatasetPreprocesado.csv\", sep=\";\",index = False) #sep es el separado, por defector es \",\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "(100, 9)\n",
            "       Edad  Consumo-alchol  ...  habito-fumar_0  habito-fumar_1\n",
            "0  0.173970       -0.192006  ...             1.0             0.0\n",
            "1  2.245043       -0.192006  ...             0.0             1.0\n",
            "2 -1.400045        1.008032  ...             0.0             0.0\n",
            "3  0.671028        1.008032  ...             0.0             0.0\n",
            "4  0.008284       -0.192006  ...             0.0             0.0\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8uqn5YIwku3",
        "colab_type": "code",
        "outputId": "4920784f-29d1-4460-bcd4-453361ce7314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
        "\n",
        "#Ahora preparamos el perceptron. Importamos las neuronas simples y el modelo secuencial\n",
        "#Modelo secuencial quiere decir que agregaremos capas y se conectarán de manera automática, \n",
        "#Dense es la librería de neuronas simples.\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.models import model_from_json\n",
        "print('Librerías importadas')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Librerías importadas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAiSlmhuwsaW",
        "colab_type": "code",
        "outputId": "67f9642c-9a69-4a31-b965-ba32ac232eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksnhofh6iKKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Guardar pesos y la arquitectura de la red en un archivo \n",
        "\n",
        "def guardarRNN(model,nombreArchivoModelo,nombreArchivoPesos):\n",
        "    print(\"Guardando Red Neuronal en Archivo\")  \n",
        "    # serializar modelo a JSON\n",
        "\n",
        "    # Guardar los Pesos (weights)\n",
        "    model.save_weights(nombreArchivoPesos+'.h5')\n",
        "\n",
        "    # Guardar la Arquitectura del modelo\n",
        "    with open(nombreArchivoModelo+'.json', 'w') as f:\n",
        "        f.write(model.to_json())\n",
        "\n",
        "    print(\"Red Neuronal Grabada en Archivo\")   \n",
        "    \n",
        "def cargarRNN(nombreArchivoModelo,nombreArchivoPesos):\n",
        "        \n",
        "    # Cargar la Arquitectura desde el archivo JSON\n",
        "    with open(nombreArchivoModelo+'.json', 'r') as f:\n",
        "        model = model_from_json(f.read())\n",
        "\n",
        "    # Cargar Pesos (weights) en el nuevo modelo\n",
        "    model.load_weights(nombreArchivoPesos+'.h5')  \n",
        "\n",
        "    print(\"Red Neuronal Cargada desde Archivo\") \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmud1HhtxDVu",
        "colab_type": "code",
        "outputId": "af45a76a-428b-4976-d8eb-10fc5ecceb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "#Construcción del Modelo o Arquitectura de Redes Neoronales\n",
        "model = Sequential()\n",
        "\n",
        "#La primera capa Dense recibe el numero de variables, que es la segunda dimensión de la matriz X, esto es X_train.shape[1]\n",
        "#La primera capa tiene 32 neuronas. La función de activación es la función rectificadora.\n",
        "model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "#La segunda capa tiene 64 neuronas. La función de activación es la función rectificadora.\n",
        "model.add(Dense(64, activation='relu'))\n",
        "#La capa de salida tiene 1 neurona. La capa de salida debe tener la misma dimensión como de cantidad de salidas queremos,\n",
        "#por ejemplo, en este caso la salida \"Survived\" solo requiere 0 y 1. Puesto que 0 o 1 ocupan solo un valor dentro de cada dato,\n",
        "#entonces 1 neurona es suficiente. La función de activación es sigmoide para clasificación por probabilidad.\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#Como tenemos dos posibles salidas \"0 o 1\", vamos a escoger que el error lo trate como una clasificación binaria, \n",
        "#el optimizador será nuestra función derivada que nos ayudará a determinar hacia donde mover los pesos.\n",
        "model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['acc']) #ADADELTA: An Adaptive Learning Rate Method\n",
        "\n",
        "#imprimir arquitectura de la red\n",
        "model.summary()\n",
        "\n",
        "#Entrenamiento: \n",
        "\n",
        "#Entrenaremos por 100 epochs, el batch_size es un argumento importante, porque representa cada cuántos datos va a actualizar\n",
        "#los pesos. Este es el método del gradiente descendiente estocástico que hace el proceso más eficiente y preciso.\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=64, verbose=0)\n",
        "score = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Resultado en Train:')\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "\n",
        "#Fase de Testing\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Resultado en Test:')\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "\n",
        "#mostrar pesos de la red\n",
        "#print(model.get_weights())\n",
        "\n",
        "#Guardar pesos y la arquitectura de la red en un archivo \n",
        "\n",
        "nombreArchivoModelo='arquitectura_prueba'\n",
        "nombreArchivoPesos='pesos_prueba'\n",
        "guardarRNN(model,nombreArchivoModelo,nombreArchivoPesos)\n",
        "\n",
        "#Cargar pesos y la arquitectura\n",
        "model2=cargarRNN(nombreArchivoModelo,nombreArchivoPesos) \n",
        "\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['acc']) #ADADELTA: An Adaptive Learning Rate Method\n",
        "score = model2.evaluate(X_train, y_train, verbose=0)\n",
        "print('Resultado en Train:')\n",
        "print(\"%s: %.2f%%\" % (model2.metrics_names[1], score[1]*100))\n",
        "\n",
        "#Fase de Testing\n",
        "print('Resultado en Test:')\n",
        "score = model2.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model2.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 32)                320       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,497\n",
            "Trainable params: 2,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Resultado en Train:\n",
            "acc: 93.75%\n",
            "Resultado en Test:\n",
            "acc: 85.00%\n",
            "Guardando Red Neuronal en Archivo\n",
            "Red Neuronal Grabada en Archivo\n",
            "Red Neuronal Cargada desde Archivo\n",
            "Resultado en Train:\n",
            "acc: 93.75%\n",
            "Resultado en Test:\n",
            "acc: 85.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdThOk0ByvBH",
        "colab_type": "code",
        "outputId": "d10a5fbf-4f1b-4835-b93a-be8cb31f5edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#Predicciones con nuevos datos\n",
        "#Temporada en la que se realizó el análisis. 1) invierno, 2) primavera, 3) verano, 4) otoño. (-1, -0.33, 0.33, 1)\n",
        "#Edad al momento del análisis. 18-36 (0, 1)\n",
        "#Enfermedades infantiles (es decir, varicela, sarampión, paperas, polio) 1) sí, 2) no. (0, 1)\n",
        "#Accidente o trauma grave 1) sí, 2) no. (0, 1)\n",
        "#Intervención quirúrgica 1) sí, 2) no. (0, 1)\n",
        "#Fiebres altas en el último año 1) hace menos de tres meses, 2) hace más de tres meses, 3) no. (-1, 0, 1)\n",
        "#Frecuencia de consumo de alcohol 1) varias veces al día, 2) todos los días, 3) varias veces a la semana, 4) una vez a la semana, 5) casi nunca o nunca (0, 1)\n",
        "#hábito de fumar 1) nunca, 2) ocasionalmente 3) diariamente. (-1, 0, 1)\n",
        "#Número de horas que pasa sentado por día ene-16 (0, 1)\n",
        "#Salida: diagnóstico normal (N), alterado (O)\n",
        "def predict(Edad=69, Accidente=1, IntQuirurgica=1, Consumoalchol=1, habitofumar=1):\n",
        "    cnames = ['Edad', 'Accidente', 'Int-Quirurgica', 'Consumo-alchol', 'habito-fumar']\n",
        "    data = [[Edad, Accidente, IntQuirurgica, Consumoalchol, habitofumar]]\n",
        "    my_X = pd.DataFrame(data=data, columns=cnames)\n",
        "    my_X = preprocesador1.transform(my_X)\n",
        "    return model.predict_classes(my_X)\n",
        "\n",
        "print('Predicción:',predict(Edad=20 ,Consumoalchol=1))\n",
        "print('Predicción:',predict(Edad=94, Accidente=1, IntQuirurgica=1 ,Consumoalchol=1,habitofumar=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicción: [[0]]\n",
            "Predicción: [[0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUpdYxJzi-a9",
        "colab_type": "text"
      },
      "source": [
        "OPTIMIZACION Y FINE TUNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz4yNW-7jMo0",
        "colab_type": "code",
        "outputId": "43040de5-63c3-4cb0-eff0-3cc8885a1d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#importamos el algoritmo cross validator, y un wrapper que permitirá usar modelos de keras con scikit learn\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.layers import Dropout\n",
        "print('Librerías importadas')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Librerías importadas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGxYTTDgjR-f",
        "colab_type": "text"
      },
      "source": [
        "Diseño de red neuronal de base y evaluacion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJi-nDEsjRc8",
        "colab_type": "code",
        "outputId": "8eff71f6-642d-4a8d-e92d-ab15d58188f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "#Evaluación del modelo original: Esto puede tardar unos 30 segundos. El modelo anterior entrena 1 sóla vez, ahora haremos una\n",
        "#media de entrenamientos con el modelo.\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "#El modelo se pasa como parámetro\n",
        "estimator = KerasClassifier(build_fn=build_model, epochs=100, batch_size=64) \n",
        "#cv es la cantidad de veces de entrenamiento del modelo\n",
        "#n_jobs es para ocupar mas de un procesador. El parámetro -1 indica que queremos utilizar todos los procesadores disponibles\n",
        "accuracies=cross_val_score(estimator, X_train, y_train, cv=10, n_jobs=-1)\n",
        "mean_acc=accuracies.mean()\n",
        "print('Precision media: ', mean_acc)\n",
        "##Como resultado al proceso de entrenamiento, tenemos un accuracy en promedio aprox. de: 0.79. Intentaremos mejorarlo.\n",
        "#Cambien optimizer='adadelta' a optimizer='adam' o a 'rmsprop'\n",
        "\n",
        "model=build_model() \n",
        "model.fit(X_train, y_train, epochs=100, batch_size=64, verbose=0)\n",
        "model.summary()\n",
        "print('Resultado en Train:')\n",
        "score = model.evaluate(X_train, y_train, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "\n",
        "#Fase de Testing\n",
        "print('Resultado en Test:')\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "\n",
        "nombreArchivoModelo='arquitectura_base'\n",
        "nombreArchivoPesos='pesos_base'\n",
        "guardarRNN(model,nombreArchivoModelo,nombreArchivoPesos)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision media:  0.85\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 32)                320       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,497\n",
            "Trainable params: 2,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Resultado en Train:\n",
            "acc: 93.75%\n",
            "Resultado en Test:\n",
            "acc: 85.00%\n",
            "Guardando Red Neuronal en Archivo\n",
            "Red Neuronal Grabada en Archivo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzr_KkFjjiuP",
        "colab_type": "text"
      },
      "source": [
        "optimizacion, fine turnig -compilacion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftno4xSdjqWi",
        "colab_type": "code",
        "outputId": "189d9d3c-eb6e-4c4f-dc99-c8f42f18e1d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "#1. Compilación: Prueba de mejores parámetros batch_size, epochs y optimizer\n",
        "#Esto recomiendo probarlo con Google Colab, puesto que se necesita 16GB en RAM y puede llegar a tardar unos 30min.\n",
        "\n",
        "def build_model(optimizer):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "\n",
        "#parámetros que queremos probar, y sus valores \n",
        "#probaremos con batch_size, epochs, y optimizador, con el fin de encontrar la mejor combinación entre estos tres parámetros.\n",
        "parameters = parameters = {'batch_size': [16,32],\n",
        "             'epochs':[100,500],\n",
        "             'optimizer': ['adadelta', 'rmsprop']}\n",
        "\n",
        "estimator = KerasClassifier(build_fn=build_model, verbose=0)\n",
        "#Ahora no le pasamos los parámetros al KerasClasifier, porque se los pasaremos a través de GridSearchCV\n",
        "#el argumento verbose=0 es para que no muestre salida, si lo dejamos en cero, no mostrará la barra de progreso del entrenamiento\n",
        "#GridSearchCV: recibe como parámetros nuestro modelo, nuestros parámetros, la medida sobre la que queremos comparar, y la \n",
        "#cantidad de veces que lo entrenará para sacar la media de accuracy.\n",
        "grid_search = GridSearchCV(estimator=estimator, param_grid=parameters, scoring='accuracy', cv=10,n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "#grid_search.best_params_\n",
        "print(grid_search.best_params_)\n",
        "#Un ejemplo de resultados es: {'batch_size': 16, 'epochs': 100, 'optimizer': 'rmsprop'}\n",
        "#Esto indica que el optimizador \"adadelta\" no es adecuado. Y es que este optimizador NO sirve para este tipo de problemas."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 32, 'epochs': 100, 'optimizer': 'adadelta'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHlOAYr_j5EA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "11. OPTIMIZACION Y FINE TUNING - DENSIDAD DE LAS CAPAS DE NEURONAS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vSLppdmj-Jj",
        "colab_type": "code",
        "outputId": "6491b350-f42a-4fe1-9b0b-7614e6aa476f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "#2. Densidad de las capas de neuronas\n",
        "#Notemos que se incluyen los mejores parámetros del paso de optimización anterior (batch_size, epochs y optimizer)\n",
        "#Esto recomiendo probarlo con Google Colab, puesto que se necesita 16GB en RAM y puede llegar a tardar unos 30min.\n",
        "def build_model(l1, l2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(l1, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(l2, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "parameters = parameters = {'l1':[16,32,64,128,256],\n",
        "                           'l2':[16,23,64,128,256]}\n",
        "\n",
        "estimator = KerasClassifier(build_fn=build_model, verbose=0, batch_size=16, epochs=100)\n",
        "grid_search = GridSearchCV(estimator=estimator, param_grid=parameters, scoring='accuracy', cv=10,n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.best_params_\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "#Resultados: {'l1': 32, 'l2': 16}\n",
        "#Los resultados indican que hubo un error en la red original, las capas van desde la más densa, a la menos densa."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'l1': 32, 'l2': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKsrDjHUnf-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "proceso con dropouts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovIM3INEnmas",
        "colab_type": "code",
        "outputId": "36ab52ff-5090-4c17-c9ee-6a6fe14eaa61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "#3. Proceso con dropouts: apagar un porcentaje de neuronas al azar con el fin de que las neuronas no se vuelvan tan \n",
        "#dependientes de los datos.\n",
        "##Esto recomiendo probarlo con Google Colab, puesto que se necesita 16GB en RAM y puede llegar a tardar unos 30min.\n",
        "def build_model(d1, d2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "    model.add(Dropout(d1))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dropout(d2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "parameters = parameters = {'d1':[0.1,0.2,0.3],\n",
        "                            'd2':[0.1,0.2,0.3]}\n",
        "\n",
        "estimator = KerasClassifier(build_fn=build_model, verbose=0, batch_size=16, epochs=100)\n",
        "grid_search = GridSearchCV(estimator=estimator, param_grid=parameters, scoring='accuracy', cv=10,n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.best_params_\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "#Resultados: {'d1':0.2, 'd2':0.3}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'d1': 0.1, 'd2': 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54pwPwTUomyw",
        "colab_type": "text"
      },
      "source": [
        "EVALUACION DE MODELO OPTIMIZADO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9mikz4Vop_q",
        "colab_type": "code",
        "outputId": "d7a70268-a28d-4c3e-c97d-44661d263757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Evaluación del Modelo Final\n",
        "\n",
        "finalModel = Sequential()\n",
        "#Finalmente, veamos como mejoró nuestro modelo, vamos a repetir el proceso de la validación cruzada.\n",
        "#Esto puede probarse localmente. Ya con los mejores parámetros evaluamos la red neuronal. Puede tardar un minuto.\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "estimator = KerasClassifier(build_fn=build_model, verbose=0, batch_size=16, epochs=100)\n",
        "accuracies = cross_val_score(estimator, X_train, y_train, cv=10, n_jobs=-1)\n",
        "mean_acc = accuracies.mean()\n",
        "std_acc = accuracies.std()\n",
        "print('accuracies: ')\n",
        "print(accuracies)\n",
        "print('Precisión media: ', mean_acc)\n",
        "print('Desviación media: ',std_acc)\n",
        "#Y el resultado es:\n",
        "#Precision media aprox.: 0.8067\n",
        "#Pasamos de un 50% precisión a un 80% de precisión, por lo que se recomienda: \n",
        "#hacer siempre el proceso de fine tunning, porque ayudará a crear modelos correctos en la mayoría de los casos.\n",
        "\n",
        "model=build_model() \n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
        "model.summary()\n",
        "\n",
        "score = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Resultado en Train:')\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "\n",
        "#Fase de Testing\n",
        "print('Resultado en Test:')\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
        "\n",
        "nombreArchivoModelo='arquitectura_optimizada'\n",
        "nombreArchivoPesos='pesos_optimizados'\n",
        "guardarRNN(model,nombreArchivoModelo,nombreArchivoPesos)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracies: \n",
            "[0.875 0.875 1.    0.75  0.75  1.    0.875 0.75  0.625 0.875]\n",
            "Precisión media:  0.8375\n",
            "Desviación media:  0.1125\n",
            "Epoch 1/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.5999 - acc: 0.7125\n",
            "Epoch 2/100\n",
            "80/80 [==============================] - 0s 97us/step - loss: 0.5297 - acc: 0.8000\n",
            "Epoch 3/100\n",
            "80/80 [==============================] - 0s 101us/step - loss: 0.4836 - acc: 0.8625\n",
            "Epoch 4/100\n",
            "80/80 [==============================] - 0s 102us/step - loss: 0.4691 - acc: 0.8375\n",
            "Epoch 5/100\n",
            "80/80 [==============================] - 0s 108us/step - loss: 0.4462 - acc: 0.8625\n",
            "Epoch 6/100\n",
            "80/80 [==============================] - 0s 106us/step - loss: 0.4150 - acc: 0.8625\n",
            "Epoch 7/100\n",
            "80/80 [==============================] - 0s 118us/step - loss: 0.4043 - acc: 0.8500\n",
            "Epoch 8/100\n",
            "80/80 [==============================] - 0s 112us/step - loss: 0.3917 - acc: 0.8500\n",
            "Epoch 9/100\n",
            "80/80 [==============================] - 0s 97us/step - loss: 0.3890 - acc: 0.8625\n",
            "Epoch 10/100\n",
            "80/80 [==============================] - 0s 92us/step - loss: 0.4074 - acc: 0.8625\n",
            "Epoch 11/100\n",
            "80/80 [==============================] - 0s 114us/step - loss: 0.3802 - acc: 0.8625\n",
            "Epoch 12/100\n",
            "80/80 [==============================] - 0s 112us/step - loss: 0.3943 - acc: 0.8750\n",
            "Epoch 13/100\n",
            "80/80 [==============================] - 0s 105us/step - loss: 0.3641 - acc: 0.8750\n",
            "Epoch 14/100\n",
            "80/80 [==============================] - 0s 95us/step - loss: 0.3489 - acc: 0.8750\n",
            "Epoch 15/100\n",
            "80/80 [==============================] - 0s 97us/step - loss: 0.3374 - acc: 0.8750\n",
            "Epoch 16/100\n",
            "80/80 [==============================] - 0s 102us/step - loss: 0.3350 - acc: 0.8625\n",
            "Epoch 17/100\n",
            "80/80 [==============================] - 0s 107us/step - loss: 0.3490 - acc: 0.8750\n",
            "Epoch 18/100\n",
            "80/80 [==============================] - 0s 95us/step - loss: 0.3515 - acc: 0.8750\n",
            "Epoch 19/100\n",
            "80/80 [==============================] - 0s 97us/step - loss: 0.3378 - acc: 0.8750\n",
            "Epoch 20/100\n",
            "80/80 [==============================] - 0s 89us/step - loss: 0.3176 - acc: 0.8750\n",
            "Epoch 21/100\n",
            "80/80 [==============================] - 0s 109us/step - loss: 0.3547 - acc: 0.8750\n",
            "Epoch 22/100\n",
            "80/80 [==============================] - 0s 95us/step - loss: 0.3481 - acc: 0.8750\n",
            "Epoch 23/100\n",
            "80/80 [==============================] - 0s 124us/step - loss: 0.3048 - acc: 0.8750\n",
            "Epoch 24/100\n",
            "80/80 [==============================] - 0s 101us/step - loss: 0.3083 - acc: 0.8750\n",
            "Epoch 25/100\n",
            "80/80 [==============================] - 0s 97us/step - loss: 0.3134 - acc: 0.8750\n",
            "Epoch 26/100\n",
            "80/80 [==============================] - 0s 98us/step - loss: 0.3203 - acc: 0.8750\n",
            "Epoch 27/100\n",
            "80/80 [==============================] - 0s 104us/step - loss: 0.3174 - acc: 0.8875\n",
            "Epoch 28/100\n",
            "80/80 [==============================] - 0s 108us/step - loss: 0.2886 - acc: 0.8750\n",
            "Epoch 29/100\n",
            "80/80 [==============================] - 0s 102us/step - loss: 0.2849 - acc: 0.8750\n",
            "Epoch 30/100\n",
            "80/80 [==============================] - 0s 109us/step - loss: 0.3202 - acc: 0.8750\n",
            "Epoch 31/100\n",
            "80/80 [==============================] - 0s 103us/step - loss: 0.3399 - acc: 0.8750\n",
            "Epoch 32/100\n",
            "80/80 [==============================] - 0s 97us/step - loss: 0.3057 - acc: 0.8750\n",
            "Epoch 33/100\n",
            "80/80 [==============================] - 0s 119us/step - loss: 0.3062 - acc: 0.8750\n",
            "Epoch 34/100\n",
            "80/80 [==============================] - 0s 112us/step - loss: 0.3124 - acc: 0.8875\n",
            "Epoch 35/100\n",
            "80/80 [==============================] - 0s 106us/step - loss: 0.2968 - acc: 0.8750\n",
            "Epoch 36/100\n",
            "80/80 [==============================] - 0s 103us/step - loss: 0.3014 - acc: 0.8750\n",
            "Epoch 37/100\n",
            "80/80 [==============================] - 0s 101us/step - loss: 0.2833 - acc: 0.8750\n",
            "Epoch 38/100\n",
            "80/80 [==============================] - 0s 98us/step - loss: 0.2887 - acc: 0.8750\n",
            "Epoch 39/100\n",
            "80/80 [==============================] - 0s 103us/step - loss: 0.2864 - acc: 0.8750\n",
            "Epoch 40/100\n",
            "80/80 [==============================] - 0s 110us/step - loss: 0.3023 - acc: 0.8625\n",
            "Epoch 41/100\n",
            "80/80 [==============================] - 0s 97us/step - loss: 0.2522 - acc: 0.8750\n",
            "Epoch 42/100\n",
            "80/80 [==============================] - 0s 102us/step - loss: 0.2911 - acc: 0.8750\n",
            "Epoch 43/100\n",
            "80/80 [==============================] - 0s 94us/step - loss: 0.2663 - acc: 0.8625\n",
            "Epoch 44/100\n",
            "80/80 [==============================] - 0s 97us/step - loss: 0.2870 - acc: 0.8875\n",
            "Epoch 45/100\n",
            "80/80 [==============================] - 0s 108us/step - loss: 0.2926 - acc: 0.8750\n",
            "Epoch 46/100\n",
            "80/80 [==============================] - 0s 110us/step - loss: 0.2857 - acc: 0.8750\n",
            "Epoch 47/100\n",
            "80/80 [==============================] - 0s 118us/step - loss: 0.2848 - acc: 0.8625\n",
            "Epoch 48/100\n",
            "80/80 [==============================] - 0s 99us/step - loss: 0.2880 - acc: 0.8875\n",
            "Epoch 49/100\n",
            "80/80 [==============================] - 0s 96us/step - loss: 0.2676 - acc: 0.8750\n",
            "Epoch 50/100\n",
            "80/80 [==============================] - 0s 115us/step - loss: 0.2634 - acc: 0.8750\n",
            "Epoch 51/100\n",
            "80/80 [==============================] - 0s 93us/step - loss: 0.3330 - acc: 0.8750\n",
            "Epoch 52/100\n",
            "80/80 [==============================] - 0s 102us/step - loss: 0.2896 - acc: 0.8750\n",
            "Epoch 53/100\n",
            "80/80 [==============================] - 0s 95us/step - loss: 0.2544 - acc: 0.8875\n",
            "Epoch 54/100\n",
            "80/80 [==============================] - 0s 103us/step - loss: 0.2885 - acc: 0.8750\n",
            "Epoch 55/100\n",
            "80/80 [==============================] - 0s 101us/step - loss: 0.2426 - acc: 0.8750\n",
            "Epoch 56/100\n",
            "80/80 [==============================] - 0s 106us/step - loss: 0.2485 - acc: 0.8875\n",
            "Epoch 57/100\n",
            "80/80 [==============================] - 0s 109us/step - loss: 0.2945 - acc: 0.8750\n",
            "Epoch 58/100\n",
            "80/80 [==============================] - 0s 98us/step - loss: 0.2667 - acc: 0.8625\n",
            "Epoch 59/100\n",
            "80/80 [==============================] - 0s 109us/step - loss: 0.2832 - acc: 0.8750\n",
            "Epoch 60/100\n",
            "80/80 [==============================] - 0s 123us/step - loss: 0.2798 - acc: 0.8750\n",
            "Epoch 61/100\n",
            "80/80 [==============================] - 0s 92us/step - loss: 0.2734 - acc: 0.8875\n",
            "Epoch 62/100\n",
            "80/80 [==============================] - 0s 125us/step - loss: 0.2948 - acc: 0.8750\n",
            "Epoch 63/100\n",
            "80/80 [==============================] - 0s 97us/step - loss: 0.2568 - acc: 0.8750\n",
            "Epoch 64/100\n",
            "80/80 [==============================] - 0s 109us/step - loss: 0.2739 - acc: 0.9000\n",
            "Epoch 65/100\n",
            "80/80 [==============================] - 0s 101us/step - loss: 0.2574 - acc: 0.8625\n",
            "Epoch 66/100\n",
            "80/80 [==============================] - 0s 91us/step - loss: 0.2505 - acc: 0.8750\n",
            "Epoch 67/100\n",
            "80/80 [==============================] - 0s 117us/step - loss: 0.2506 - acc: 0.8875\n",
            "Epoch 68/100\n",
            "80/80 [==============================] - 0s 110us/step - loss: 0.2541 - acc: 0.8875\n",
            "Epoch 69/100\n",
            "80/80 [==============================] - 0s 97us/step - loss: 0.2453 - acc: 0.8875\n",
            "Epoch 70/100\n",
            "80/80 [==============================] - 0s 106us/step - loss: 0.2369 - acc: 0.8875\n",
            "Epoch 71/100\n",
            "80/80 [==============================] - 0s 99us/step - loss: 0.2689 - acc: 0.8875\n",
            "Epoch 72/100\n",
            "80/80 [==============================] - 0s 110us/step - loss: 0.2420 - acc: 0.9000\n",
            "Epoch 73/100\n",
            "80/80 [==============================] - 0s 108us/step - loss: 0.2256 - acc: 0.8875\n",
            "Epoch 74/100\n",
            "80/80 [==============================] - 0s 94us/step - loss: 0.2455 - acc: 0.9000\n",
            "Epoch 75/100\n",
            "80/80 [==============================] - 0s 96us/step - loss: 0.2412 - acc: 0.9125\n",
            "Epoch 76/100\n",
            "80/80 [==============================] - 0s 79us/step - loss: 0.2327 - acc: 0.8875\n",
            "Epoch 77/100\n",
            "80/80 [==============================] - 0s 143us/step - loss: 0.2089 - acc: 0.9000\n",
            "Epoch 78/100\n",
            "80/80 [==============================] - 0s 111us/step - loss: 0.2097 - acc: 0.8875\n",
            "Epoch 79/100\n",
            "80/80 [==============================] - 0s 96us/step - loss: 0.2379 - acc: 0.8875\n",
            "Epoch 80/100\n",
            "80/80 [==============================] - 0s 115us/step - loss: 0.2316 - acc: 0.9000\n",
            "Epoch 81/100\n",
            "80/80 [==============================] - 0s 102us/step - loss: 0.2428 - acc: 0.8875\n",
            "Epoch 82/100\n",
            "80/80 [==============================] - 0s 97us/step - loss: 0.2293 - acc: 0.8875\n",
            "Epoch 83/100\n",
            "80/80 [==============================] - 0s 102us/step - loss: 0.2021 - acc: 0.8625\n",
            "Epoch 84/100\n",
            "80/80 [==============================] - 0s 91us/step - loss: 0.2499 - acc: 0.8750\n",
            "Epoch 85/100\n",
            "80/80 [==============================] - 0s 97us/step - loss: 0.2099 - acc: 0.9125\n",
            "Epoch 86/100\n",
            "80/80 [==============================] - 0s 128us/step - loss: 0.2185 - acc: 0.8625\n",
            "Epoch 87/100\n",
            "80/80 [==============================] - 0s 108us/step - loss: 0.2294 - acc: 0.9000\n",
            "Epoch 88/100\n",
            "80/80 [==============================] - 0s 113us/step - loss: 0.2144 - acc: 0.8625\n",
            "Epoch 89/100\n",
            "80/80 [==============================] - 0s 128us/step - loss: 0.2140 - acc: 0.9125\n",
            "Epoch 90/100\n",
            "80/80 [==============================] - 0s 98us/step - loss: 0.2130 - acc: 0.9125\n",
            "Epoch 91/100\n",
            "80/80 [==============================] - 0s 111us/step - loss: 0.2250 - acc: 0.9000\n",
            "Epoch 92/100\n",
            "80/80 [==============================] - 0s 102us/step - loss: 0.1961 - acc: 0.9125\n",
            "Epoch 93/100\n",
            "80/80 [==============================] - 0s 102us/step - loss: 0.2372 - acc: 0.8875\n",
            "Epoch 94/100\n",
            "80/80 [==============================] - 0s 93us/step - loss: 0.2339 - acc: 0.9125\n",
            "Epoch 95/100\n",
            "80/80 [==============================] - 0s 93us/step - loss: 0.2038 - acc: 0.9125\n",
            "Epoch 96/100\n",
            "80/80 [==============================] - 0s 115us/step - loss: 0.2108 - acc: 0.8875\n",
            "Epoch 97/100\n",
            "80/80 [==============================] - 0s 101us/step - loss: 0.2390 - acc: 0.9000\n",
            "Epoch 98/100\n",
            "80/80 [==============================] - 0s 104us/step - loss: 0.2105 - acc: 0.8875\n",
            "Epoch 99/100\n",
            "80/80 [==============================] - 0s 96us/step - loss: 0.2222 - acc: 0.9250\n",
            "Epoch 100/100\n",
            "80/80 [==============================] - 0s 95us/step - loss: 0.2130 - acc: 0.9125\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 32)                320       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 865\n",
            "Trainable params: 865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Resultado en Train:\n",
            "acc: 92.50%\n",
            "Resultado en Test:\n",
            "acc: 90.00%\n",
            "Guardando Red Neuronal en Archivo\n",
            "Red Neuronal Grabada en Archivo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wKZzD8so8ul",
        "colab_type": "text"
      },
      "source": [
        "COMPARACION ENTRE MODELO BASE Y MODELO OPTIMIZADO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8s6b-S_o-LM",
        "colab_type": "code",
        "outputId": "bf246b5c-88ec-4fea-ffce-de855c7bddb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "#Modelo Base\n",
        "print('MODELO BASE')\n",
        "nombreArchivoModelo='arquitectura_base'\n",
        "nombreArchivoPesos='pesos_base'\n",
        "Selectedmodel=cargarRNN(nombreArchivoModelo,nombreArchivoPesos) \n",
        "\n",
        "#Selectedmodel.summary()\n",
        "\n",
        "Selectedmodel.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['acc']) #ADADELTA: An Adaptive Learning Rate Method\n",
        "print('Resultado en Train:')\n",
        "score = Selectedmodel.evaluate(X_train, y_train, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (Selectedmodel.metrics_names[1], score[1]*100))\n",
        "\n",
        "#Fase de Testing\n",
        "print('Resultado en Test:')\n",
        "score = Selectedmodel.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (Selectedmodel.metrics_names[1], score[1]*100))\n",
        "\n",
        "#Modelo optimizado\n",
        "print('MODELO OPTIMIZADO')\n",
        "nombreArchivoModelo='arquitectura_optimizada'\n",
        "nombreArchivoPesos='pesos_optimizados'\n",
        "Selectedmodel=cargarRNN(nombreArchivoModelo,nombreArchivoPesos)    \n",
        "\n",
        "#Selectedmodel.summary()\n",
        "\n",
        "Selectedmodel.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['acc']) #ADADELTA: An Adaptive Learning Rate Method\n",
        "print('Resultado en Train:')\n",
        "score = Selectedmodel.evaluate(X_train, y_train, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (Selectedmodel.metrics_names[1], score[1]*100))\n",
        "\n",
        "#Fase de Testing\n",
        "print('Resultado en Test:')\n",
        "score = Selectedmodel.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (Selectedmodel.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODELO BASE\n",
            "Red Neuronal Cargada desde Archivo\n",
            "Resultado en Train:\n",
            "acc: 93.75%\n",
            "Resultado en Test:\n",
            "acc: 85.00%\n",
            "MODELO OPTIMIZADO\n",
            "Red Neuronal Cargada desde Archivo\n",
            "Resultado en Train:\n",
            "acc: 92.50%\n",
            "Resultado en Test:\n",
            "acc: 90.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOxdyDedpn9A",
        "colab_type": "text"
      },
      "source": [
        "PREDICCION - USO DEL MODELO OPTIMIZADO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I2TVaA-pzNO",
        "colab_type": "code",
        "outputId": "3c8e174f-5011-4736-82ee-f035ef7c51ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#Predicciones con nuevos datos\n",
        "\n",
        "#La siguiente función tomará los datos de entrada, los va a integrar a una dataframe, los va a preprocesar, y \n",
        "#retornará una predicción con la salida \"0\" o \"1\", es decir, \"sobrevivió\" o \"no sobrevivió\"\n",
        "def predict(Edad=69, Accidente=1, IntQuirurgica=1, Consumoalchol=1, habitofumar=1):\n",
        "    cnames = ['Edad', 'Accidente', 'Int-Quirurgica', 'Consumo-alchol', 'habito-fumar']\n",
        "    data = [[Edad, Accidente, IntQuirurgica, Consumoalchol, habitofumar]]\n",
        "    my_X = pd.DataFrame(data=data, columns=cnames)\n",
        "    my_X = preprocesador1.transform(my_X)\n",
        "    return model.predict_classes(my_X)\n",
        "\n",
        "print('Predicción:',predict(Edad=20 ,Consumoalchol=1))\n",
        "print('Predicción:',predict(Edad=94, Accidente=1, IntQuirurgica=1 ,Consumoalchol=1,habitofumar=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicción: [[0]]\n",
            "Predicción: [[0]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}